"""
Test simplificado para verificar extracci√≥n de dimensiones del LLM de Groq.
Este test muestra exactamente qu√© responde el LLM y qu√© dimensiones se extraen.
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()
sys.path.append(str(Path(__file__).parent))

from simulation.groq_simulator import GroqCBRSimulator, GroqSimulationConfig

def test_llm_response_format():
    """Verifica el formato de respuesta del LLM."""
    
    print("="*80)
    print("TEST: FORMATO DE RESPUESTA DEL LLM DE GROQ")
    print("="*80)
    
    config = GroqSimulationConfig(
        verbose=True,
        temperature=0.3
    )
    
    simulator = GroqCBRSimulator(config)
    
    # Crear datos de prueba
    request_data = {
        'event_type': 'FORMAL_DINNER',
        'num_guests': 6,
        'season': 'SPRING',
        'price_min': 30,
        'price_max': 50,
        'required_diets': [],
        'preferred_style': None,
        'cultural_preference': 'ITALIAN'
    }
    
    menu_details = [{
        'starter': {
            'name': 'Bruschetta',
            'ingredients': ['tomate', 'albahaca', 'ajo', 'pan'],
            'price': 8
        },
        'main_course': {
            'name': 'Pasta Carbonara',
            'ingredients': ['pasta', 'huevo', 'bacon', 'queso'],
            'price': 18
        },
        'dessert': {
            'name': 'Tiramisu',
            'ingredients': ['mascarpone', 'caf√©', 'cacao'],
            'price': 7
        },
        'beverage': {
            'name': 'Vino Chianti',
            'price': 12
        },
        'total_price': 45
    }]
    
    print("\nüìã Solicitud de prueba:")
    print(f"   Evento: {request_data['event_type']}")
    print(f"   Presupuesto: {request_data['price_min']}-{request_data['price_max']}‚Ç¨")
    print(f"   Cultura: {request_data['cultural_preference']}")
    print(f"   Precio del men√∫: {menu_details[0]['total_price']}‚Ç¨")
    
    print("\nü§ñ Llamando a Groq LLM...")
    print("="*80)
    
    # Llamar al m√©todo de evaluaci√≥n
    result = simulator._evaluate_single_request(request_data, menu_details)
    
    print("\nüìÑ RESPUESTA COMPLETA DEL LLM:")
    print("="*80)
    print(result['evaluation_text'])
    print("="*80)
    
    print("\nüìä SCORES EXTRA√çDOS:")
    print(f"   General:  {result.get('score', 'N/A')}")
    print(f"   Precio:   {result.get('price_score', 'N/A')}")
    print(f"   Cultura:  {result.get('cultural_score', 'N/A')}")
    print(f"   Sabor:    {result.get('flavor_score', 'N/A')}")
    
    # Verificar si las dimensiones son diferentes del overall
    price_score = result.get('price_score', result['score'])
    cultural_score = result.get('cultural_score', result['score'])
    flavor_score = result.get('flavor_score', result['score'])
    overall_score = result['score']
    
    print("\nüîç AN√ÅLISIS:")
    
    if price_score != overall_score or cultural_score != overall_score or flavor_score != overall_score:
        print("‚úÖ Las dimensiones son DIFERENTES del score general")
        print("   ‚Üí El LLM S√ç est√° evaluando dimensiones por separado")
    else:
        print("‚ö†Ô∏è  Todas las dimensiones son IGUALES al score general")
        print("   ‚Üí Posible problema:")
        print("      1. El LLM no est√° siguiendo el formato solicitado")
        print("      2. La extracci√≥n por regex no encuentra los valores")
        print("      3. Se est√° usando el fallback (mismo valor para todo)")
    
    # Buscar los patrones en el texto
    print("\nüîé B√öSQUEDA DE PATRONES EN LA RESPUESTA:")
    text = result['evaluation_text'].upper()
    
    patterns = {
        'PRECIO': 'PRECIO:' in text or 'PRICE:' in text,
        'CULTURA': 'CULTURA:' in text or 'CULTURAL:' in text,
        'SABOR': 'SABOR:' in text or 'FLAVOR:' in text,
        'GENERAL': 'GENERAL:' in text or 'OVERALL:' in text
    }
    
    for pattern, found in patterns.items():
        symbol = "‚úÖ" if found else "‚ùå"
        print(f"   {symbol} Patr√≥n '{pattern}:' {'encontrado' if found else 'NO encontrado'}")
    
    if not any(patterns.values()):
        print("\nüí° SUGERENCIA:")
        print("   El LLM no est√° usando el formato solicitado.")
        print("   Puede que necesitemos:")
        print("   - Ajustar el prompt para ser m√°s espec√≠fico")
        print("   - Mejorar los patrones de extracci√≥n")
        print("   - Usar un ejemplo en el prompt")

if __name__ == "__main__":
    if not os.environ.get("GROQ_API_KEY"):
        print("‚ùå ERROR: GROQ_API_KEY no configurada")
        print("Crea archivo .env con: GROQ_API_KEY=tu_key")
        exit(1)
    
    test_llm_response_format()
